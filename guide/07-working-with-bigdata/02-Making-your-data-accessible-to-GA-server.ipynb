{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make your data accessible to the ArcGIS Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting, storing, managing and analyzing large quantities of numbers, figures, and files is not a new business activity. But referring to these numbers, figures and files as big data is relatively recent.\n",
    " \n",
    "The GeoAnalytics Server expands your ArcGIS Enterprise deployment providing functionality and services to process and analyze big data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the GeoAnalytics tools, your data needs to be in one of the following formats:\n",
    "\n",
    "- Feature layers (hosted, hosted feature layer views, and from feature services)\n",
    "- Feature collections\n",
    "- [Big data file shares](https://gis.fema.gov/arcgis/help/en/portal/latest/use/what-is-a-big-data-file-share.htm) registered with ArcGIS GeoAnalytics Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Big data file shares\n",
    "The GeoAnalytics server allows you to register datasets in a format called a [big data file share](http://enterprise.arcgis.com/en/server/latest/get-started/windows/what-is-a-big-data-file-share.htm). Big data file shares are items on your Web GIS, and can reference data in any of the following data sources:\n",
    " - File Share - a directory of datasets stored locally or shared across a network\n",
    " - HDFS - an [Hadoop Distributed File System](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#Introduction) directory of datasets\n",
    " - [Apache Hive](https://hive.apache.org/) - a metastore database\n",
    " - Cloud Store - an [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/) container or [Amazon Web Services S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html) \n",
    "\n",
    "When writing results to a big data file share, you can use the following output GeoAnalytics Tools:\n",
    "\n",
    "- File share\n",
    "- HDFS\n",
    "- Cloud store\n",
    "\n",
    "The following file types are supported as datasets for input and output in big data file shares:\n",
    "\n",
    "- Delimited files (such as .csv, .tsv, and .txt)\n",
    "- Shapefiles (.shp)\n",
    "- Parquet files (.gz.parquet)\n",
    "- ORC files (orc.crc)\n",
    "\n",
    "Storing your data in a big data file share datastore benefits you because:\n",
    " - The GeoAnalytics tools read your data only when they are executed, which allows you to update or add data to these locations.\n",
    " - You can use partitioned data as a single dataset.\n",
    " - Big data file shares are flexible in how time and geometry are defined, allowing data in multiple formats in a single dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preparing your data\n",
    "To register a file share or an HDFS, you need to format your datasets as subfolders within a single parent folder and register the parent folder. This parent folder becomes a `datastore`, and each subfolder becomes a `dataset`. For instance, to register 2 datasets representing earthquakes and hurricanes, your folder hierarchy would look like below:\n",
    "```\n",
    "|---FileShareFolder         <-- register as a datastore\n",
    "   |---Earthquakes          <-- dataset 1\n",
    "      |---1960              \n",
    "         |---01_1960.csv\n",
    "         |---02_1960.csv\n",
    "      |---1961              \n",
    "         |---01_1961.csv\n",
    "         |---02_1961.csv\n",
    "   |---Hurricanes           <-- dataset 2\n",
    "      |---atlantic_hur.shp\n",
    "      |---pacific_hur.shp\n",
    "```\n",
    "Learn more about preparing your big data file share datasets [here](http://server.arcgis.com/en/server/latest/get-started/windows/what-is-a-big-data-file-share.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to enterprise GIS\n",
    "from arcgis.gis import GIS\n",
    "import arcgis.geoanalytics\n",
    "portal_gis = GIS(\"https://pythonapi.playground.esri.com/portal\", \"arcgis_python\", \"amazing_arcgis_123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring your GIS supports GeoAnalytics\n",
    "It is best practice to confirm proper configuration of your Enterprise to support the GeoAnalytics Server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that GeoAnalytics is supported \n",
    "arcgis.geoanalytics.is_supported()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering big data file shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`get_datastores()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.geoanalytics.toc.html#get-datastores) method of the `geoanalytics` module returns a [`DatastoreManager`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#datastoremanager) object that lets you search for and manage the big data file share items as Python API  [`Datastore`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#datastore) objects on your GeoAnalytics server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatastoreManager for https://pythonapi.playground.esri.com/ga/admin>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata_datastore_manager = arcgis.geoanalytics.get_datastores()\n",
    "bigdata_datastore_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can register your data as a big data file share using the `add_bigdata()` method on a `DatastoreManager` object. Ensure the datasets are stored in a format compatible with the GeoAnalytics server as seen earlier in this guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "item = bigdata_datastore_manager.add_bigdata(\"Name_of_big_data_file_share\", r\"\\\\<file_share_path>\\<big_data_folder>\")\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created cloud store for cloud_store\n"
     ]
    }
   ],
   "source": [
    "data_item = bigdata_datastore_manager.add_cloudstore(name='cloud_store', \n",
    "                                         conn_str='''{\"accessKeyId\":\"<provide key here>\",\n",
    "                                                      \"secretAccessKey\":\"<provide secret key here>\",\n",
    "                                                      \"region\":\"<provide region here>\",\n",
    "                                                      \"defaultEndpointsProtocol\":\"<probide https or http here>\",\n",
    "                                                      \"credentialType\":\"accesskey\"}''', \n",
    "                                         object_store=\"esri-delhi-store\", \n",
    "                                         provider='amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cloudStores/cloud_store1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Big Data file share for ServiceCallsOrleans\n"
     ]
    }
   ],
   "source": [
    "data_item = bigdata_datastore_manager.add_bigdata(name=\"ServiceCallsOrleans\", \n",
    "                                                  server_path=data_item.path, \n",
    "                                                  connection_type='dataStore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Big Data file share for ServiceCallsOrleans\n"
     ]
    }
   ],
   "source": [
    "data_item = bigdata_datastore_manager.add_bigdata(\"ServiceCallsOrleans\", r\"\\\\machinename\\datastore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for big data file shares on datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [`search()`](https://esri.github.io/arcgis-python-api/apidoc/html/arcgis.gis.toc.html#arcgis.gis.DatastoreManager.search) method on a `DatastoreManager` object to search for `Datastores`. Observe in the output below the item titled _FileShareFolder_ as illustrated in the example file structure above is registered as a big data file share in the portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Datastore title:\"/bigDataFileShares/NYC_taxi_data15\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/all_hurricanes\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/NYCdata\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_1848_1900\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/ServiceCallsOrleans\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_dask_csv\" type:\"bigDataFileShare\">,\n",
       " <Datastore title:\"/bigDataFileShares/hurricanes_dask_shp\" type:\"bigDataFileShare\">]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdata_fileshares = bigdata_datastore_manager.search()\n",
    "bigdata_fileshares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get datasets from a big data file share datastore\n",
    "Let's use the `datasets` property on a `Datastore` object to find out how many datasets are available and then list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder = bigdata_fileshares[1]\n",
    "file_share_datasets = file_share_folder.datasets\n",
    "len(file_share_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 0:   hurricanes\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(file_share_datasets)):\n",
    "    print(\"{:<10}{:<3}{}\".format(\"Dataset \" + str(i) + \":\", \"\", file_share_datasets[i]['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'hurricanes',\n",
       " 'format': {'type': 'shapefile', 'extension': 'shp'},\n",
       " 'schema': {'fields': [{'name': 'serial_num', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'season', 'type': 'esriFieldTypeBigInteger'},\n",
       "   {'name': 'num', 'type': 'esriFieldTypeBigInteger'},\n",
       "   {'name': 'basin', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'sub_basin', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'name', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'iso_time', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'nature', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'latitude', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'longitude', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'wind_wmo_', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'pres_wmo_', 'type': 'esriFieldTypeBigInteger'},\n",
       "   {'name': 'center', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'wind_wmo1', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'pres_wmo1', 'type': 'esriFieldTypeDouble'},\n",
       "   {'name': 'track_type', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'size', 'type': 'esriFieldTypeString'},\n",
       "   {'name': 'Wind', 'type': 'esriFieldTypeBigInteger'}]},\n",
       " 'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "  'spatialReference': {'wkid': 102682, 'latestWkid': 3452}},\n",
       " 'time': {'timeType': 'instant',\n",
       "  'timeReference': {'timeZone': 'UTC'},\n",
       "  'fields': [{'name': 'iso_time',\n",
       "    'formats': ['yyyy-MM-dd HH:mm:ss', 'MM/dd/yyyy HH:mm']}]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's view the json schema of the hurricanes dataset for a sample\n",
    "file_share_datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get path of the big data file share item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bigDataFileShares/ServiceCallsOrleans'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the data is accessible to all Geoanalytics servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get schema of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a big data file share is created, the GeoAnalytics server samples the datasets to generate a [manifest](https://enterprise.arcgis.com/en/server/latest/get-started/windows/understanding-the-big-data-file-share-manifest.htm), which outlines the data schema and specifies any time and geometry fields. A query of the resulting manifest returns each dataset's schema.. This process can take a few minutes depending on the size of your data. Once processed, querying the manifest property returns the schema of the datasets in your big data file share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'calls',\n",
       "   'format': {'quoteChar': '\"',\n",
       "    'fieldDelimiter': ',',\n",
       "    'hasHeaderRow': True,\n",
       "    'encoding': 'UTF-8',\n",
       "    'escapeChar': '\"',\n",
       "    'recordTerminator': '\\n',\n",
       "    'type': 'delimited',\n",
       "    'extension': 'csv'},\n",
       "   'schema': {'fields': [{'name': 'NOPD_Item', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Type_', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TypeText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Priority', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'MapX', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'MapY', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'TimeCreate', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeDispatch', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeArrive', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeClosed', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Disposition', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'DispositionText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'BLOCK_ADDRESS', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Zip', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'PoliceDistrict', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'Location', 'type': 'esriFieldTypeString'}]},\n",
       "   'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "    'spatialReference': {'wkid': 4326},\n",
       "    'fields': [{'name': 'MapX', 'formats': ['x']},\n",
       "     {'name': 'MapY', 'formats': ['y']}]},\n",
       "   'time': {'timeType': 'instant',\n",
       "    'timeReference': {'timeZone': 'UTC'},\n",
       "    'fields': [{'name': 'TimeCreate',\n",
       "      'formats': ['MM/dd/yyyy hh:mm:ss a']}]}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest = file_share_folder.manifest\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit a big data file share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial reference of the dataset is set to 4326, but we know this data is from New Orleans, Louisiana, and is actually stored in the [Louisiana State Plane Coordinate System](https://spatialreference.org/ref/esri/102682/html/). We need to edit the manifest with the correct spatial reference: {\"wkid\": 102682, \"latestWkid\": 3452}. Knowing the location where this data belongs to and the coordinate system which contains geospatial information of this dataset, we will edit our manifest. This will set the correct spatial reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest['datasets'][0]['geometry']['spatialReference'] = { \"wkid\": 102682, \"latestWkid\": 3452 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_share_folder.manifest = manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'calls',\n",
       "   'format': {'quoteChar': '\"',\n",
       "    'fieldDelimiter': ',',\n",
       "    'hasHeaderRow': True,\n",
       "    'encoding': 'UTF-8',\n",
       "    'escapeChar': '\"',\n",
       "    'recordTerminator': '\\n',\n",
       "    'type': 'delimited',\n",
       "    'extension': 'csv'},\n",
       "   'schema': {'fields': [{'name': 'NOPD_Item', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Type_', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TypeText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Priority', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'MapX', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'MapY', 'type': 'esriFieldTypeDouble'},\n",
       "     {'name': 'TimeCreate', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeDispatch', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeArrive', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'TimeClosed', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Disposition', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'DispositionText', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'BLOCK_ADDRESS', 'type': 'esriFieldTypeString'},\n",
       "     {'name': 'Zip', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'PoliceDistrict', 'type': 'esriFieldTypeBigInteger'},\n",
       "     {'name': 'Location', 'type': 'esriFieldTypeString'}]},\n",
       "   'geometry': {'geometryType': 'esriGeometryPoint',\n",
       "    'spatialReference': {'wkid': 102682, 'latestWkid': 3452},\n",
       "    'fields': [{'name': 'MapX', 'formats': ['x']},\n",
       "     {'name': 'MapY', 'formats': ['y']}]},\n",
       "   'time': {'timeType': 'instant',\n",
       "    'timeReference': {'timeZone': 'UTC'},\n",
       "    'fields': [{'name': 'TimeCreate',\n",
       "      'formats': ['MM/dd/yyyy hh:mm:ss a']}]}}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_share_folder.manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for big data file shares items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a big data file share to the Geoanalytics server adds a corresponding [big data file share item](https://enterprise.arcgis.com/en/portal/latest/use/what-is-a-big-data-file-share.htm) on the portal. We can search for these types of items using the item_type parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"bigDataFileShares_ServiceCallsOrleans\" type:Big Data File Share owner:admin>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = gis.content.search(\"bigDataFileShares_ServiceCallsOrleans\", item_type = \"big data file share\", max_items=40)\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = search_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://dev0006300.esri.com/portal/home/item.html?id=9577a976f9ea4f6b8407e6c43833777f' target='_blank'>\n",
       "                        <img src='https://dev0006300.esri.com/portal/portalimages/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://dev0006300.esri.com/portal/home/item.html?id=9577a976f9ea4f6b8407e6c43833777f' target='_blank'><b>bigDataFileShares_ServiceCallsOrleans</b>\n",
       "                        </a>\n",
       "                        <br/><img src='https://dev0006300.esri.com/portal/home/js/jsapi/esri/css/images/item_type_icons/layers16.png' style=\"vertical-align:middle;\">Big Data File Share by admin\n",
       "                        <br/>Last Modified: November 11, 2019\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"bigDataFileShares_ServiceCallsOrleans\" type:Big Data File Share owner:admin>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to preform some cool analysis on your data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
